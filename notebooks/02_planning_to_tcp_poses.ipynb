{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning to TCP Poses üìê\n",
    "\n",
    "In the previous notebook we saw how to plan paths between joint configurations.\n",
    "In this notebook we will explore how planning to TCP poses opens doors to many interesting possibilities, such as:\n",
    "- üí• **Filtering** e.g. pregrasp configurations to ensure moving the the grasp pose does not collide with the environment\n",
    "- ü•á **Selecting** optimal paths, e.g. the shortest, smoothest, fastest after time parametrization or most clearance\n",
    "- üìä **Ranking** goal joint configurations and planning to them iteratively, selecting the first path that is found. This ranking could be based on the distance of the goal joint configuration to the a desirable joint configuration, e.g the start joint configuration.\n",
    "\n",
    "**The 4-Step Process**\n",
    "\n",
    "Let's break down how we approach TCP pose planning:\n",
    "1. üßÆ **IK Solutions:** Calculate candidate goal joint configurations from the goal TCP pose.\n",
    "2. ü§î **Rank & Prioritize (Optional):** Rank those candidates\n",
    "3. üó∫Ô∏è **Plan Paths:** Try planning paths to the candidates.\n",
    "4. üèÜ **Select the Best (Optional):** Choose the optimal path based on your criteria.\n",
    "\n",
    "\n",
    "\n",
    "<!-- **Why Planning to TCP Poses Matters**\n",
    "\n",
    "- ‚ú® **Flexibility:** A single TCP pose often corresponds to multiple possible joint configurations for a 6-DOF robot.\n",
    "- üí° **Strategic choices:** This opens doors! We can filter pre-grasp configurations for collision-free grasps, optimize paths based on smoothness or speed, and more.\n",
    "\n",
    "\n",
    "However, in this notebook we will show how planning to TCP poses opens interesting opportunities.\n",
    "\n",
    "A key fact to know, is that for a given TCP pose in the workspace of a 6-DOF robot, there will be several joint configurations that can achieve that pose. \n",
    "For some robots, such as the universal robots we use at our lab, you can analytically calculate the inverse kinematics to find all the joint configurations that can achieve a given TCP pose.\n",
    "\n",
    "This finite set of possible goal configurations provide an interesting opportunity.\n",
    "For example, if the TCP pose we plan to is a pregrasp pose from which we want to move linearly to a grasp pose, we can filter the pregrasp joint configurations to only select the from which we can move to the grasp pose without colliding with the environment.\n",
    "\n",
    "Another possiblity with multiple joint configurations is that we can plan paths to each of them and then select the best path according to some criteria. For example, we might want to select the shortest path, or the smoothest path, or the path that can be executed the fastest after time parametrization.\n",
    "\n",
    "However, if any path is good enough, and we care mostly about planning time, we can rank the goal joint configurations, and plan to them iteratively, and select the first path that is found. This ranking could for example be based on the distance goal joint configuration to the a desirable joint configuration .e.g the start joint configuration.\n",
    "\n",
    "\n",
    "The way we achieve planning to TCP poses is by using a four-step process:\n",
    "1. Calculate the inverse kinematics of the goal TCP pose to find the candidate goal joint configurations.\n",
    "2. Optional: rank the goal joint configurations\n",
    "3. Attempt to plan a path to the goal joint configuration(s)\n",
    "4. Optional: select the best path -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the scene & collision checker üèóÔ∏èÔ∏è\n",
    "\n",
    "For more details about this, see the [`airo-drake`](https://github.com/airo-ugent/airo-drake) notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydrake.planning import RobotDiagramBuilder\n",
    "from airo_drake import SingleArmScene, add_floor, add_manipulator, add_meshcat, finish_build\n",
    "from pydrake.planning import SceneGraphCollisionChecker\n",
    "\n",
    "robot_diagram_builder = RobotDiagramBuilder()\n",
    "\n",
    "meshcat = add_meshcat(robot_diagram_builder)\n",
    "arm_index, gripper_index = add_manipulator(robot_diagram_builder, \"ur3e\", \"robotiq_2f_85\", static_gripper=True)\n",
    "add_floor(robot_diagram_builder)\n",
    "robot_diagram, context = finish_build(robot_diagram_builder)\n",
    "\n",
    "scene = SingleArmScene(robot_diagram, arm_index, gripper_index, meshcat)\n",
    "\n",
    "\n",
    "collision_checker = SceneGraphCollisionChecker(\n",
    "    model=scene.robot_diagram,\n",
    "    robot_model_instances=[scene.arm_index, scene.gripper_index],\n",
    "    edge_step_size=0.125,  # Arbitrary value: we don't use the CheckEdgeCollisionFree\n",
    "    env_collision_padding=0.005,\n",
    "    self_collision_padding=0.005,\n",
    ")\n",
    "\n",
    "collision_checker.CheckConfigCollisionFree(np.zeros(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_joints = np.deg2rad([0, -90, 90, -90, -90, 0])\n",
    "\n",
    "print(collision_checker.CheckConfigCollisionFree(start_joints))\n",
    "\n",
    "plant = scene.robot_diagram.plant()\n",
    "plant_context = plant.GetMyContextFromRoot(context)\n",
    "plant.SetPositions(plant_context, scene.arm_index, start_joints)\n",
    "scene.robot_diagram.ForcedPublish(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the motion planner üß≠\n",
    "\n",
    "To enable planning to TCP poses, we need to provide an additional argument to the `SingleArmOmplPlanner` constructor, namely an `inverse_kinematics_fn` that returns a list of joint configurations for a given TCP pose.\n",
    "\n",
    "### 2.1 `inverse_kinematics_fn` üßÆ\n",
    "In this notebook we will be using the analytical inverse kinematics from the [`ur-analytic-ik`](https://github.com/Victorlouisdg/ur-analytic-ik) Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ur_analytic_ik import ur3e\n",
    "from airo_typing import HomogeneousMatrixType, JointConfigurationType\n",
    "from airo_drake import visualize_frame\n",
    "\n",
    "tcp_transform = np.identity(4)\n",
    "tcp_transform[2, 3] = 0.175  # 175 mm in z\n",
    "\n",
    "\n",
    "def inverse_kinematics_fn(tcp_pose: HomogeneousMatrixType) -> list[JointConfigurationType]:\n",
    "    solutions = ur3e.inverse_kinematics_with_tcp(tcp_pose, tcp_transform)\n",
    "    return solutions\n",
    "\n",
    "\n",
    "goal_pose = np.identity(4)\n",
    "\n",
    "X = np.array([-1.0, 0.0, 0.0])\n",
    "Y = np.array([0.0, 1.0, 0.0])\n",
    "Z = np.array([0.0, 0.0, -1.0])\n",
    "top_down_orientation = np.column_stack([X, Y, Z])\n",
    "goal_pose[:3, :3] = top_down_orientation\n",
    "goal_pose[:3, 3] = [0.17, 0.0, 0.0]\n",
    "\n",
    "visualize_frame(scene.meshcat, \"goal_pose\", goal_pose)\n",
    "\n",
    "solutions = inverse_kinematics_fn(goal_pose)\n",
    "\n",
    "with np.printoptions(precision=3, suppress=True):\n",
    "    for solution in solutions:\n",
    "        print(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airo_drake import animate_joint_configurations\n",
    "\n",
    "animate_joint_configurations(scene.meshcat, scene.robot_diagram, scene.arm_index, solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 `SingleArmOmplPlanner` üß≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airo_planner import SingleArmOmplPlanner\n",
    "\n",
    "\n",
    "planner = SingleArmOmplPlanner(collision_checker.CheckConfigCollisionFree, inverse_kinematics_fn=inverse_kinematics_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Planning to TCP poses üó∫\n",
    "\n",
    "### 3.1 Choosing the shortest path üìè\n",
    "\n",
    "The default behavior of `SingleArmOmplPlanner`  is planning to all valid goal joint configurations and selecting the shortest path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = planner.plan_to_tcp_pose(start_joints, goal_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_joint_configurations(scene.meshcat, scene.robot_diagram, scene.arm_index, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Double checking the path lengths:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airo_drake import calculate_joint_path_length\n",
    "\n",
    "path_lengths = [calculate_joint_path_length(p) for p in planner._all_paths]\n",
    "\n",
    "print(\"Path lengths\")\n",
    "for i, path_length in enumerate(path_lengths):\n",
    "    print(f\"{i}: {path_length:.2f}\")\n",
    "\n",
    "print(f\"\\nLength of path that planner returned: {calculate_joint_path_length(path):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Ranking goal configuration desirability üîÄ\n",
    "\n",
    "It's common to prefer that the robot arm stays close specific desirable configurations, such as:\n",
    "- the start joint configuration üèÅ\n",
    "- a home configuration üè°\n",
    "\n",
    "We let the planner know these goal configuration preferences by setting the:\n",
    "- `rank_goal_configurations_fn` attribute of the `SingleArmOmplPlanner`.\n",
    "\n",
    "In `airo-planner` we provide a `rank_by_distance_to_desirable_configurations()` function that we can use for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airo_planner.selection.goal_selection import rank_by_distance_to_desirable_configurations\n",
    "\n",
    "ranked_solutions = rank_by_distance_to_desirable_configurations(solutions, [start_joints])\n",
    "\n",
    "np.printoptions(precision=3, suppress=True)\n",
    "\n",
    "print(\"Distances to ranked solutions\")\n",
    "for i, solution in enumerate(ranked_solutions):\n",
    "    distance = np.linalg.norm(solution - start_joints)\n",
    "    print(f\"{distance:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner.rank_goal_configurations_fn = rank_by_distance_to_desirable_configurations\n",
    "\n",
    "path = planner.plan_to_tcp_pose(start_joints, goal_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nLength of path that planner returned: {calculate_joint_path_length(path):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_joint_configurations(scene.meshcat, scene.robot_diagram, scene.arm_index, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Filtering goal configurations üßπ\n",
    "\n",
    "**Filtering** is possibliy the most powerful feature of planning to TCP poses.\n",
    "By filtering the goal joint configurations, we can ensure that the robot goes to configurations that enable downstream tasks. \n",
    "For example, you want to make sure that end configuration of the path to the pregrasp pose is such that you can move linearly to the grasp pose without colliding with the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airo_planner.interfaces import SingleArmPlanner\n",
    "from pydrake.trajectories import Trajectory\n",
    "\n",
    "\n",
    "from airo_drake import visualize_frame\n",
    "\n",
    "\n",
    "# grasp_location = np.array([0.2, 0.5, 0.5]) # This moves the robot through a singularlity for some start configurations\n",
    "grasp_location = np.array([0.2, 0.3, 0.2])\n",
    "\n",
    "gripper_forward_direction = np.array([1, 0, 0])\n",
    "\n",
    "Z = gripper_forward_direction / np.linalg.norm(gripper_forward_direction)\n",
    "Y = np.array([0, 0, -1])  # 0, 0, 1 is also an option\n",
    "X = np.cross(Y, Z)\n",
    "\n",
    "grasp_orientation = np.column_stack([X, Y, Z])\n",
    "grasp_pose = np.identity(4)\n",
    "grasp_pose[0:3, 0:3] = grasp_orientation\n",
    "grasp_pose[0:3, 3] = grasp_location\n",
    "\n",
    "pregrasp_pose = grasp_pose.copy()\n",
    "pregrasp_pose[0:3, 3] -= 0.25 * gripper_forward_direction\n",
    "\n",
    "visualize_frame(scene.meshcat, \"pregrasp_pose\", pregrasp_pose)\n",
    "visualize_frame(scene.meshcat, \"grasp_pose\", grasp_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ur_analytic_ik import ur3e\n",
    "\n",
    "tcp_transform = np.identity(4)\n",
    "tcp_transform[2, 3] = 0.175  # 175 mm in z\n",
    "\n",
    "start_configurations = ur3e.inverse_kinematics_with_tcp(pregrasp_pose, tcp_transform)\n",
    "goal_configurations = ur3e.inverse_kinematics_with_tcp(grasp_pose, tcp_transform)\n",
    "\n",
    "start_configurations = np.array(start_configurations).squeeze()\n",
    "goal_configurations = np.array(goal_configurations).squeeze()\n",
    "\n",
    "len(start_configurations), len(goal_configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_collisions_as_emojis(is_collision_free: list[bool]):\n",
    "    \"\"\"Displays an emoji-based visualization of a path's collisions.\n",
    "\n",
    "    Example output: \"‚úÖ‚úÖüí•‚úÖ‚úÖ‚úÖüí•‚úÖ‚úÖ‚úÖ‚úÖ\"\n",
    "\n",
    "    Args:\n",
    "        is_collision_free: A list of booleans, where True indicates no collision.\n",
    "\n",
    "    Returns:\n",
    "        A string of emojis representing the collision status of the path.\n",
    "    \"\"\"\n",
    "    emojis = [\"‚úÖ\" if is_free else \"üí•\" for is_free in is_collision_free]\n",
    "    emoji_str = \"\".join(emojis)\n",
    "    return emoji_str\n",
    "\n",
    "\n",
    "print(path_collisions_as_emojis(collision_checker.CheckConfigsCollisionFree(start_configurations)))\n",
    "print(path_collisions_as_emojis(collision_checker.CheckConfigsCollisionFree(goal_configurations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrake.trajectories import PiecewisePose\n",
    "from pydrake.math import RigidTransform\n",
    "from airo_drake import discretize_drake_pose_trajectory\n",
    "\n",
    "\n",
    "rigid_transforms = [RigidTransform(pose) for pose in [pregrasp_pose, grasp_pose]]\n",
    "times = np.linspace(0, 1, len(rigid_transforms))\n",
    "pose_trajectory = PiecewisePose.MakeLinear(times=times, poses=rigid_transforms)\n",
    "\n",
    "\n",
    "tcp_path = discretize_drake_pose_trajectory(pose_trajectory).poses\n",
    "\n",
    "for i, tcp_pose in enumerate(tcp_path):\n",
    "    visualize_frame(scene.meshcat, f\"tcp_path/pose_{i}\", tcp_pose, length=0.05, opacity=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airo_drake import calculate_valid_joint_paths, calculate_joint_paths\n",
    "\n",
    "\n",
    "def ur3e_inverse_kinematics(tcp_pose: HomogeneousMatrixType) -> list[JointConfigurationType]:\n",
    "    solutions_1x6 = ur3e.inverse_kinematics_with_tcp(tcp_pose, tcp_transform)\n",
    "    solutions = [solution.squeeze() for solution in solutions_1x6]\n",
    "    return solutions\n",
    "\n",
    "\n",
    "joint_paths_ = calculate_joint_paths(tcp_path, ur3e_inverse_kinematics)\n",
    "\n",
    "for i, path in enumerate(joint_paths_):\n",
    "    print(f\"{path_collisions_as_emojis(collision_checker.CheckConfigsCollisionFree(path))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_paths = calculate_valid_joint_paths(\n",
    "    tcp_path, ur3e_inverse_kinematics, collision_checker.CheckConfigCollisionFree\n",
    ")\n",
    "\n",
    "for i, path in enumerate(joint_paths):\n",
    "    print(f\"{path_collisions_as_emojis(collision_checker.CheckConfigsCollisionFree(path))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animate_joint_configurations(scene.meshcat, scene.robot_diagram, scene.arm_index, joint_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from airo_planner.selection.goal_selection import filter_with_distance_to_configurations\n",
    "\n",
    "path_starts = [path[0] for path in joint_paths]\n",
    "\n",
    "filter_fn = partial(filter_with_distance_to_configurations, joint_configurations_close=path_starts)\n",
    "\n",
    "filter_fn(start_configurations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this a filtering example: we want to filter out the grasp paths that collide with the environment\n",
    "\n",
    "# def plan_to_grasp(planner: SingleArmPlanner, grasp_pose: HomogeneousMatrixType) -> Trajectory:\n",
    "#     pass\n",
    "#     # attempt planning the the grasp pose directly\n",
    "#     #   if all goals in collision try backing-off to a pregrasp pose\n",
    "#     #   time parametrize both paths and concatenate them\n",
    "from airo_typing import InverseKinematicsFunctionType, JointConfigurationCheckerType\n",
    "\n",
    "\n",
    "def plan_pregrasp(\n",
    "    grasp_pose: HomogeneousMatrixType,\n",
    "    start_configuration: JointConfigurationType,\n",
    "    inverse_kinematics_fn: InverseKinematicsFunctionType,\n",
    "    is_state_valid_fn_pregrasp: JointConfigurationCheckerType,\n",
    "    is_state_valid_fn_grasp: JointConfigurationCheckerType,\n",
    "):\n",
    "\n",
    "    pregrasp_distances_to_try = [0.05, 0.1, 0.15, 0.2, 0.25]\n",
    "\n",
    "    planner = SingleArmOmplPlanner(is_state_valid_fn_pregrasp, inverse_kinematics_fn=inverse_kinematics_fn)\n",
    "\n",
    "    for distance in pregrasp_distances_to_try:\n",
    "        # 1. Compute pregrasp pose\n",
    "        pregrasp_pose = grasp_pose.copy()\n",
    "        pregrasp_pose[0:3, 3] -= distance * pregrasp_pose[0:3, 2]\n",
    "\n",
    "        # 2. Compute grasp TCP path\n",
    "        rigid_transforms = [RigidTransform(pose) for pose in [pregrasp_pose, grasp_pose]]\n",
    "        times = np.linspace(0, 1, len(rigid_transforms))\n",
    "        pose_trajectory = PiecewisePose.MakeLinear(times=times, poses=rigid_transforms)\n",
    "        tcp_path = discretize_drake_pose_trajectory(pose_trajectory).poses\n",
    "\n",
    "        # 3 Compute valid grasp joint paths\n",
    "        joint_paths = calculate_valid_joint_paths(tcp_path, ur3e_inverse_kinematics, is_state_valid_fn_grasp)\n",
    "        path_starts = [path[0] for path in joint_paths]\n",
    "\n",
    "        # 4 plan to pregrasp tcp poses, filtering on the valid grasp joint paths\n",
    "        filter_fn = partial(filter_with_distance_to_configurations, joint_configurations_close=path_starts)\n",
    "\n",
    "        planner.filter_goal_configurations_fn = filter_fn\n",
    "        path = planner.plan_to_tcp_pose(start_configuration, pregrasp_pose)\n",
    "\n",
    "        if path is not None:\n",
    "            return path\n",
    "\n",
    "    # Exhausted all pregrasp poses to try\n",
    "\n",
    "\n",
    "path = plan_pregrasp(\n",
    "    grasp_pose,\n",
    "    start_joints,\n",
    "    ur3e_inverse_kinematics,\n",
    "    collision_checker.CheckConfigCollisionFree,\n",
    "    collision_checker.CheckConfigCollisionFree,\n",
    ")\n",
    "\n",
    "animate_joint_configurations(scene.meshcat, scene.robot_diagram, scene.arm_index, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloth-competition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
