{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning to TCP Poses üìê\n",
    "\n",
    "In the previous notebook we saw how to plan paths between joint configurations.\n",
    "In this notebook we will explore how planning to TCP poses opens doors to many interesting possibilities, such as:\n",
    "- üí• **Filtering** e.g. pregrasp configurations to ensure moving the the grasp pose does not collide with the environment\n",
    "- ü•á **Selecting** optimal paths, e.g. the shortest, smoothest or fastest after time parametrization\n",
    "- üìä **Ranking** goal joint configurations and planning to them iteratively, selecting the first path that is found. This ranking could be based on the distance of the goal joint configuration to the a desirable joint configuration, e.g the start joint configuration.\n",
    "\n",
    "**The 4-Step Process**\n",
    "\n",
    "Let's break down how we approach TCP pose planning:\n",
    "1. üßÆ **IK Solutions:** Calculate candidate goal joint configurations from the goal TCP pose.\n",
    "2. ü§î **Rank & Prioritize (Optional):** Rank those candidates\n",
    "3. üó∫Ô∏è **Plan Paths:** Try planning paths to the candidates.\n",
    "4. üèÜ **Select the Best (Optional):** Choose the optimal path based on your criteria.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- **Why Planning to TCP Poses Matters**\n",
    "\n",
    "- ‚ú® **Flexibility:** A single TCP pose often corresponds to multiple possible joint configurations for a 6-DOF robot.\n",
    "- üí° **Strategic choices:** This opens doors! We can filter pre-grasp configurations for collision-free grasps, optimize paths based on smoothness or speed, and more.\n",
    "\n",
    "\n",
    "However, in this notebook we will show how planning to TCP poses opens interesting opportunities.\n",
    "\n",
    "A key fact to know, is that for a given TCP pose in the workspace of a 6-DOF robot, there will be several joint configurations that can achieve that pose. \n",
    "For some robots, such as the universal robots we use at our lab, you can analytically calculate the inverse kinematics to find all the joint configurations that can achieve a given TCP pose.\n",
    "\n",
    "This finite set of possible goal configurations provide an interesting opportunity.\n",
    "For example, if the TCP pose we plan to is a pregrasp pose from which we want to move linearly to a grasp pose, we can filter the pregrasp joint configurations to only select the from which we can move to the grasp pose without colliding with the environment.\n",
    "\n",
    "Another possiblity with multiple joint configurations is that we can plan paths to each of them and then select the best path according to some criteria. For example, we might want to select the shortest path, or the smoothest path, or the path that can be executed the fastest after time parametrization.\n",
    "\n",
    "However, if any path is good enough, and we care mostly about planning time, we can rank the goal joint configurations, and plan to them iteratively, and select the first path that is found. This ranking could for example be based on the distance goal joint configuration to the a desirable joint configuration .e.g the start joint configuration.\n",
    "\n",
    "\n",
    "The way we achieve planning to TCP poses is by using a four-step process:\n",
    "1. Calculate the inverse kinematics of the goal TCP pose to find the candidate goal joint configurations.\n",
    "2. Optional: rank the goal joint configurations\n",
    "3. Attempt to plan a path to the goal joint configuration(s)\n",
    "4. Optional: select the best path -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the scene & collision checker üèóÔ∏èÔ∏è\n",
    "\n",
    "For more details about this, see the [`airo-drake`](https://github.com/airo-ugent/airo-drake) notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydrake.planning import RobotDiagramBuilder\n",
    "from airo_drake import SingleArmScene, add_floor, add_manipulator, add_meshcat, finish_build\n",
    "from pydrake.planning import SceneGraphCollisionChecker\n",
    "\n",
    "robot_diagram_builder = RobotDiagramBuilder()\n",
    "\n",
    "meshcat = add_meshcat(robot_diagram_builder)\n",
    "arm_index, gripper_index = add_manipulator(robot_diagram_builder, \"ur3e\", \"robotiq_2f_85\", static_gripper=True)\n",
    "add_floor(robot_diagram_builder)\n",
    "robot_diagram, context = finish_build(robot_diagram_builder)\n",
    "\n",
    "scene = SingleArmScene(robot_diagram, arm_index, gripper_index, meshcat)\n",
    "\n",
    "\n",
    "collision_checker = SceneGraphCollisionChecker(\n",
    "    model=scene.robot_diagram,\n",
    "    robot_model_instances=[scene.arm_index, scene.gripper_index],\n",
    "    edge_step_size=0.125,  # Arbitrary value: we don't use the CheckEdgeCollisionFree\n",
    "    env_collision_padding=0.005,\n",
    "    self_collision_padding=0.005,\n",
    ")\n",
    "\n",
    "collision_checker.CheckConfigCollisionFree(np.zeros(6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the motion planner üß≠\n",
    "\n",
    "To enable planning to TCP poses, we need to provide an additional argument to the `SingleArmOmplPlanner` constructor, namely an `inverse_kinematics_fn` that returns a list of joint configurations for a given TCP pose.\n",
    "\n",
    "In this notebook we will be using the analytical inverse kinematics from the [`ur-analytic-ik`](https://github.com/Victorlouisdg/ur-analytic-ik) Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ur_analytic_ik import ur3e\n",
    "from airo_typing import HomogeneousMatrixType, JointConfigurationType\n",
    "from airo_drake import visualize_frame\n",
    "\n",
    "tcp_transform = np.identity(4)\n",
    "tcp_transform[2, 3] = 0.175  # 175 mm in z\n",
    "\n",
    "\n",
    "def inverse_kinematics_fn(tcp_pose: HomogeneousMatrixType) -> list[JointConfigurationType]:\n",
    "    solutions = ur3e.inverse_kinematics_with_tcp(tcp_pose, tcp_transform)\n",
    "    return solutions\n",
    "\n",
    "\n",
    "goal_pose = np.identity(4)\n",
    "\n",
    "X = np.array([-1.0, 0.0, 0.0])\n",
    "Y = np.array([0.0, 1.0, 0.0])\n",
    "Z = np.array([0.0, 0.0, -1.0])\n",
    "top_down_orientation = np.column_stack([X, Y, Z])\n",
    "goal_pose[:3, :3] = top_down_orientation\n",
    "goal_pose[:3, 3] = [0.2, 0.0, 0.0]\n",
    "\n",
    "visualize_frame(scene.meshcat, \"goal_pose\", goal_pose)\n",
    "\n",
    "solutions = inverse_kinematics_fn(goal_pose)\n",
    "\n",
    "# with np.printoptions(precision=3, suppress=True):\n",
    "for solution in solutions:\n",
    "    print(solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from airo_drake import animate_joint_configurations\n",
    "\n",
    "animate_joint_configurations(scene.meshcat, scene.robot_diagram, scene.arm_index, solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloth-competition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
